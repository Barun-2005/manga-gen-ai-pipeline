{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üé® MangaGen - AI Manga Generation Pipeline\n",
        "\n",
        "Generate complete manga pages with consistent characters from text prompts!\n",
        "\n",
        "**Features:**\n",
        "- üìù Story ‚Üí Scene JSON (Gemini 2.0 Flash)\n",
        "- üé® SDXL + IP-Adapter for consistent characters\n",
        "- üí¨ Smart dialogue bubble placement\n",
        "- üìÑ PDF output with zip download\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Prerequisites\n",
        "\n",
        "Before running, add these secrets in **Kaggle Settings ‚Üí Add-ons ‚Üí Secrets**:\n",
        "1. `GEMINI_API_KEY` - Get from https://aistudio.google.com/app/apikey\n",
        "2. `HF_TOKEN` (optional) - HuggingFace token for model downloads\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Cell 1: Clone Repository & Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Clone the repository\n",
        "cd /kaggle/working\n",
        "if [ -d \"manga-gen\" ]; then\n",
        "    echo \"Repository already exists, pulling latest...\"\n",
        "    cd manga-gen && git pull\n",
        "else\n",
        "    echo \"Cloning repository...\"\n",
        "    git clone --branch mvp/kaggle-flux https://github.com/Barun-2005/manga-gen-ai-pipeline.git manga-gen\n",
        "    cd manga-gen\n",
        "fi\n",
        "echo \"\"\n",
        "echo \"Latest commit:\"\n",
        "git log -1 --oneline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies using our Kaggle-specific script\n",
        "import os\n",
        "os.chdir('/kaggle/working/manga-gen')\n",
        "!bash install_kaggle_deps.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CRITICAL: Verify diffusers is installed!\n",
        "print(\"üîç Verifying critical packages...\")\n",
        "try:\n",
        "    import diffusers\n",
        "    print(f\"‚úÖ diffusers: {diffusers.__version__}\")\n",
        "except ImportError:\n",
        "    print(\"‚ùå diffusers NOT FOUND - installing now...\")\n",
        "    !pip install diffusers==0.27.2 transformers==4.40.2 accelerate==0.29.3\n",
        "    import diffusers\n",
        "    print(f\"‚úÖ diffusers: {diffusers.__version__}\")\n",
        "\n",
        "import torch\n",
        "print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
        "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîë Cell 2: Set Up API Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Add manga-gen to path\n",
        "sys.path.insert(0, '/kaggle/working/manga-gen')\n",
        "os.chdir('/kaggle/working/manga-gen')\n",
        "\n",
        "# Load API keys from Kaggle Secrets\n",
        "try:\n",
        "    from kaggle_secrets import UserSecretsClient\n",
        "    secrets = UserSecretsClient()\n",
        "    \n",
        "    # Required: Gemini API Key\n",
        "    os.environ['GEMINI_API_KEY'] = secrets.get_secret('GEMINI_API_KEY')\n",
        "    print(\"‚úÖ GEMINI_API_KEY loaded from Kaggle secrets\")\n",
        "    \n",
        "    # Optional: HuggingFace Token\n",
        "    try:\n",
        "        os.environ['HF_TOKEN'] = secrets.get_secret('HF_TOKEN')\n",
        "        print(\"‚úÖ HF_TOKEN loaded\")\n",
        "    except:\n",
        "        print(\"‚ÑπÔ∏è HF_TOKEN not set (optional)\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not load secrets: {e}\")\n",
        "    print(\"\")\n",
        "    print(\"üîß To add secrets:\")\n",
        "    print(\"   1. Click 'Add-ons' menu at top\")\n",
        "    print(\"   2. Select 'Secrets'\")\n",
        "    print(\"   3. Add 'GEMINI_API_KEY' with your API key\")\n",
        "    print(\"\")\n",
        "    print(\"Get your Gemini API key at: https://aistudio.google.com/app/apikey\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è Cell 3: Configuration\n",
        "\n",
        "Customize your manga generation settings here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# üé® MANGA CONFIGURATION - EDIT THIS!\n",
        "# ============================================\n",
        "\n",
        "# Your story prompt - describe your manga scene\n",
        "STORY_PROMPT = \"\"\"\n",
        "Astra, a determined space scavenger with messy silver hair and a grease-stained orange jumpsuit, \n",
        "explores a derelict spaceship. She finds a glowing blue artifact in the cockpit.\n",
        "\"\"\".strip()\n",
        "\n",
        "# Visual style: \"bw_manga\" (black & white) or \"color_anime\" (colorful)\n",
        "STYLE = \"bw_manga\"\n",
        "\n",
        "# Panel layout: \"2x2\" (4 panels), \"vertical_webtoon\" (3 panels), \"3_panel\", \"single\"\n",
        "LAYOUT = \"2x2\"\n",
        "\n",
        "# Generation quality (higher = better but slower)\n",
        "INFERENCE_STEPS = 25  # 20-30 for testing, 40-50 for quality\n",
        "GUIDANCE_SCALE = 7.5  # 6-9 recommended\n",
        "\n",
        "# ============================================\n",
        "\n",
        "print(\"üìã Configuration:\")\n",
        "print(f\"   Story: {STORY_PROMPT[:80]}...\")\n",
        "print(f\"   Style: {STYLE}\")\n",
        "print(f\"   Layout: {LAYOUT}\")\n",
        "print(f\"   Steps: {INFERENCE_STEPS}\")\n",
        "print(f\"   Guidance: {GUIDANCE_SCALE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Cell 4: Generate Scene Plan (Gemini)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Generate scene plan using Gemini\n",
        "!python scripts/generate_scene_json.py \"{STORY_PROMPT}\" --style {STYLE} --layout {LAYOUT} --output scene_plan.json\n",
        "\n",
        "# Display the generated scene plan\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üìã Generated Scene Plan\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "if os.path.exists('scene_plan.json'):\n",
        "    with open('scene_plan.json', 'r') as f:\n",
        "        scene_plan = json.load(f)\n",
        "    \n",
        "    print(f\"\\nTitle: {scene_plan.get('title', 'Untitled')}\")\n",
        "    print(f\"Style: {scene_plan.get('style', 'unknown')}\")\n",
        "    print(f\"Layout: {scene_plan.get('layout', 'unknown')}\")\n",
        "    \n",
        "    print(f\"\\nüìö Characters ({len(scene_plan.get('characters', []))})\")\n",
        "    for char in scene_plan.get('characters', []):\n",
        "        print(f\"   ‚Ä¢ {char['name']}: {char['hair_color']} hair\")\n",
        "    \n",
        "    print(f\"\\nüñºÔ∏è Panels ({len(scene_plan.get('panels', []))})\")\n",
        "    for panel in scene_plan.get('panels', []):\n",
        "        print(f\"   {panel['panel_number']}. [{panel['camera_angle']}] {panel['description'][:50]}...\")\n",
        "else:\n",
        "    print(\"‚ùå Scene plan generation failed. Check the error above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üñºÔ∏è Cell 5: Generate Panel Images (GPU)\n",
        "\n",
        "This is the main image generation step. Uses:\n",
        "- SDXL for high-quality anime/manga style\n",
        "- IP-Adapter for character consistency (if installed)\n",
        "\n",
        "**Time estimate:** ~3-8 minutes for 4 panels on Kaggle T4 GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "# Check GPU availability\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    print(f\"‚úÖ GPU Available: {gpu_name} ({gpu_mem:.1f} GB)\")\n",
        "    USE_MOCK = False\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU detected - using mock mode\")\n",
        "    USE_MOCK = True\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "\n",
        "# Build command\n",
        "cmd = f\"python scripts/generate_panels.py --scene scene_plan.json --output outputs/ --steps {INFERENCE_STEPS} --guidance {GUIDANCE_SCALE}\"\n",
        "if USE_MOCK:\n",
        "    cmd += \" --mock\"\n",
        "\n",
        "print(f\"\\nüé® Running: {cmd}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "start_time = time.time()\n",
        "\n",
        "!{cmd}\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "print(f\"\\n‚è±Ô∏è Generation time: {elapsed/60:.1f} minutes\")\n",
        "\n",
        "# If it was very fast and not mock mode, something might be wrong\n",
        "if elapsed < 30 and not USE_MOCK:\n",
        "    print(\"\\n‚ö†Ô∏è Generation was very fast - might have fallen back to mock mode!\")\n",
        "    print(\"   Check if diffusers is installed: !pip show diffusers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display generated panels\n",
        "from IPython.display import display, Image as IPImage\n",
        "import glob\n",
        "\n",
        "print(\"\\nüñºÔ∏è Generated Panels:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "panels = sorted(glob.glob('outputs/panel_*.png'))\n",
        "if panels:\n",
        "    for panel in panels:\n",
        "        if 'with_bubbles' not in panel:\n",
        "            print(f\"\\n{os.path.basename(panel)}\")\n",
        "            display(IPImage(filename=panel, width=400))\n",
        "else:\n",
        "    print(\"‚ùå No panels found! Check errors above.\")\n",
        "\n",
        "# Show character references if they exist\n",
        "refs = glob.glob('outputs/character_refs/*.png')\n",
        "if refs:\n",
        "    print(\"\\nüì∏ Character References:\")\n",
        "    for ref in refs:\n",
        "        print(f\"\\n{os.path.basename(ref)}\")\n",
        "        display(IPImage(filename=ref, width=200))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üí¨ Cell 6: Place Dialogue Bubbles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate bubble positions\n",
        "!python scripts/place_bubbles.py --panels outputs/ --scene scene_plan.json --output bubbles.json\n",
        "\n",
        "# Display bubble data\n",
        "if os.path.exists('bubbles.json'):\n",
        "    with open('bubbles.json', 'r') as f:\n",
        "        bubbles = json.load(f)\n",
        "    \n",
        "    print(\"\\nüí¨ Bubble Placements:\")\n",
        "    for panel_key, panel_bubbles in bubbles.items():\n",
        "        print(f\"   {panel_key}: {len(panel_bubbles)} bubble(s)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÑ Cell 7: Compose Final Page & PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compose final page with bubbles\n",
        "!python scripts/compose_page.py --panels outputs/ --bubbles bubbles.json --scene scene_plan.json --output outputs/\n",
        "\n",
        "# Display final page\n",
        "if os.path.exists('outputs/manga_page.png'):\n",
        "    print(\"\\nüé® Final Manga Page:\")\n",
        "    display(IPImage(filename='outputs/manga_page.png', width=600))\n",
        "    \n",
        "    # Show file info\n",
        "    print(\"\\nüìÅ Output Files:\")\n",
        "    for f in ['outputs/manga_page.png', 'outputs/manga_page.pdf', 'manga_output.zip']:\n",
        "        if os.path.exists(f):\n",
        "            size_mb = os.path.getsize(f) / 1024 / 1024\n",
        "            print(f\"   ‚úÖ {f} ({size_mb:.2f} MB)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Cell 8: Download Your Manga!\n",
        "\n",
        "Use the Kaggle file browser (left sidebar) to download `manga_output.zip`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import display, HTML, FileLink\n",
        "\n",
        "print('\\n' + '='*50)\n",
        "print('üéâ YOUR MANGA IS READY!')\n",
        "print('='*50)\n",
        "\n",
        "zip_path = 'manga_output.zip'\n",
        "\n",
        "if os.path.exists(zip_path):\n",
        "    size_mb = os.path.getsize(zip_path) / 1024 / 1024\n",
        "    print(f'\\nüì¶ File: {zip_path} ({size_mb:.2f} MB)')\n",
        "    \n",
        "    print('\\nüì• HOW TO DOWNLOAD:')\n",
        "    print('   1. Look at the LEFT SIDEBAR (file browser)')\n",
        "    print('   2. Navigate to: kaggle/working/manga-gen/')\n",
        "    print('   3. Right-click on \"manga_output.zip\"')\n",
        "    print('   4. Click \"Download\"')\n",
        "    \n",
        "    print('\\n   Or try clicking the link below:')\n",
        "    try:\n",
        "        display(FileLink(zip_path))\n",
        "    except:\n",
        "        print('   (Use file browser instead)')\n",
        "    \n",
        "    print('\\nüìã Zip contains:')\n",
        "    print('   ‚Ä¢ manga_page.pdf - Final manga with bubbles')\n",
        "    print('   ‚Ä¢ manga_page.png - Full resolution page')\n",
        "    print('   ‚Ä¢ panel_*.png - Individual panels')\n",
        "    print('   ‚Ä¢ character_refs/ - Character reference images')\n",
        "else:\n",
        "    print('‚ö†Ô∏è Zip file not found!')\n",
        "    print('\\n   Check the compose_page.py output above for errors.')\n",
        "    print('   You can download individual files from outputs/ folder.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìä Pipeline Summary\n",
        "\n",
        "| Step | Component | Time |\n",
        "|------|-----------|------|\n",
        "| 1 | Clone & Install | ~1 min |\n",
        "| 2 | API Keys | instant |\n",
        "| 3 | Scene Plan (Gemini) | ~5 sec |\n",
        "| 4 | Panel Generation (SDXL) | ~3-8 min |\n",
        "| 5 | Bubble Placement | ~10 sec |\n",
        "| 6 | PDF Composition | ~5 sec |\n",
        "\n",
        "**Total time:** ~5-10 minutes\n",
        "\n",
        "---\n",
        "\n",
        "Made with ‚ù§Ô∏è by Barun | [GitHub](https://github.com/Barun-2005/manga-gen-ai-pipeline)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}